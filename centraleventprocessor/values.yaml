# Default values for central-event-processor.
# This is a YAML-formatted file.

# Declare global configurations
global:
  config: {}

# Declare variables to be passed into your templates.

replicaCount: 1
image:
  repository: mojaloop/central-event-processor
  tag: v10.5.0
  pullPolicy: Always

## Pod scheduling preferences.
## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
affinity: {}

## Node labels for pod assignment
## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector
nodeSelector: {}

## Set toleration for scheduler
## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
tolerations: []

init:
  enabled: true
  kafka:
    name: wait-for-kafka
    repository: solsson/kafka
    tag: latest
    pullPolicy: Always
    command: "until ./bin/kafka-broker-api-versions.sh --bootstrap-server $kafka_host:$kafka_port; do echo waiting for Kafka; sleep 2; done;"
    env: {}
    ## Env example
    # env:
    #   envItem1:
    #     name: hello
    #     value: world
    #
  mongodb:
    name: wait-for-mongodb
    repository: bitnami/mongodb
    tag: latest
    pullPolicy: Always
    command: "mongo mongodb://$mongo_host:$mongo_port --eval \"db.adminCommand('ping')\""

service:
  name: central-event-processor
  type: ClusterIP
  externalPort: 80
  internalPort: 3080

  annotations: {}

  # This allows one to point the service to an external backend.
  # This is useful for local development where one wishes to hijack
  # the communication from the service to the node layer and point
  # to a specific endpoint (IP, Port, etc).
  external:
    enabled: false
    # 10.0.2.2 is the magic IP for the host on virtualbox's network
    ip: 10.0.2.2
    ports:
      api:
        name: central-event-processor
        externalPort: 3080

readinessProbe:
  enabled: true
  httpGet:
    path: /health
  initialDelaySeconds: 30
  periodSeconds: 15

livenessProbe:
  enabled: true
  httpGet:
    path: /health
  initialDelaySeconds: 30
  periodSeconds: 15

ingress:
  enabled: true
  # Used to create an Ingress record.
  hosts:
    api: central-event-processor.local

  externalPath: /

  annotations:
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"

  tls:
    # Secrets must be manually created in the namespace.
    # - secretName: chart-example-tls
    #   hosts:
    #     - chart-example.local

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #  cpu: 100m
  #  memory: 128Mi
  # requests:
  #  cpu: 100m
  #  memory: 128Mi

config:
  ## Kafka Configuration
  # this can be set if the dependency chart for kafka is disabled. If 'kafka_host' is commented out, then the name of the dependency chart will be used.
  kafka_host: '$release_name-kafka'
  kafka_port: 9092
  PORT: 3080
  mongo_host: '$release_name-mongodb'
  mongo_port: 27017
  mongo_user: mojaloop
  mongo_password: password
  mongo_database: mojaloop
  central_ledger_admin_host: '$release_name-centralledger-service'
  central_ledger_admin_port: 80
  hub_participant:
    name: hub
  log_level: info
  log_transport: file

# kafka:
#   enabled: true
#   nameOverride: kafka
#   # ------------------------------------------------------------------------------
#   # Kafka:
#   # ------------------------------------------------------------------------------

#   ## The StatefulSet installs 3 pods by default
#   replicas: 1

#   ## The kafka image repository
#   image: "confluentinc/cp-kafka"

#   ## The kafka image tag
#   imageTag: "4.0.1-1"

#   ## Specify a imagePullPolicy
#   ## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images
#   imagePullPolicy: "IfNotPresent"

#   ## Configure resource requests and limits
#   ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
#   resources: {}
#     # limits:
#     #   cpu: 200m
#     #   memory: 1536Mi
#     # requests:
#     #   cpu: 100m
#     #   memory: 1024Mi
#   kafkaHeapOptions: "-Xmx1G -Xms1G"

#   ## The StatefulSet Update Strategy which Kafka will use when changes are applied.
#   ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
#   updateStrategy:
#     type: "OnDelete"

#   ## Start and stop pods in Parallel or OrderedReady (one-by-one.)  Note - Can not change after first release.
#   ## ref: https://kubernetes.io/docs/tutorials/stateful-application/basic-stateful-set/#pod-management-policy
#   podManagementPolicy: OrderedReady

#   ## If RBAC is enabled on the cluster, the Kafka init container needs a service account
#   ## with permissisions sufficient to apply pod labels
#   rbac:
#     enabled: true

#   ## The name of the storage class which the cluster should use.
#   # storageClass: default

#   ## The subpath within the Kafka container's PV where logs will be stored.
#   ## This is combined with `persistence.mountPath`, to create, by default: /opt/kafka/data/logs
#   logSubPath: "logs"

#   ## Use an alternate scheduler, e.g. "stork".
#   ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
#   ##
#   # schedulerName:

#   ## Pod scheduling preferences (by default keep pods within a release on separate nodes).
#   ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
#   ## By default we don't set affinity
#   affinity: {}
#   ## Alternatively, this typical example defines:
#   ## antiAffinity (to keep Kafka pods on separate pods)
#   ## and affinity (to encourage Kafka pods to be collocated with Zookeeper pods)
#   # affinity:
#   #   podAntiAffinity:
#   #     requiredDuringSchedulingIgnoredDuringExecution:
#   #     - labelSelector:
#   #         matchExpressions:
#   #         - key: app
#   #           operator: In
#   #           values:
#   #           - kafka
#   #       topologyKey: "kubernetes.io/hostname"
#   #   podAffinity:
#   #     preferredDuringSchedulingIgnoredDuringExecution:
#   #      - weight: 50
#   #        podAffinityTerm:
#   #          labelSelector:
#   #            matchExpressions:
#   #            - key: app
#   #              operator: In
#   #              values:
#   #                - zookeeper
#   #          topologyKey: "kubernetes.io/hostname"

#   ## Node labels for pod assignment
#   ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector
#   nodeSelector: {}

#   ## Readiness probe config.
#   ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/
#   ##
#   readinessProbe:
#     initialDelaySeconds: 30
#     periodSeconds: 10
#     timeoutSeconds: 5
#     successThreshold: 1
#     failureThreshold: 3

#   ## Period to wait for broker graceful shutdown (sigterm) before pod is killed (sigkill)
#   ## ref: https://kubernetes-v1-4.github.io/docs/user-guide/production-pods/#lifecycle-hooks-and-termination-notice
#   ## ref: https://kafka.apache.org/10/documentation.html#brokerconfigs controlled.shutdown.*
#   terminationGracePeriodSeconds: 60

#   # Tolerations for nodes that have taints on them.
#   # Useful if you want to dedicate nodes to just run kafka
#   # https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
#   tolerations: []
#   # tolerations:
#   # - key: "key"
#   #   operator: "Equal"
#   #   value: "value"
#   #   effect: "NoSchedule"

#   ## External access.
#   ##
#   external:
#     enabled: false
#     servicePort: 19092
#     firstListenerPort: 31090
#     domain: cluster.local
#     init:
#       image: "lwolf/kubectl_deployer"
#       imageTag: "0.4"
#       imagePullPolicy: "IfNotPresent"

#   ## Configuration Overrides. Specify any Kafka settings you would like set on the StatefulSet
#   ## here in map format, as defined in the official docs.
#   ## ref: https://kafka.apache.org/documentation/#brokerconfigs
#   ##
#   configurationOverrides:
#     "offsets.topic.replication.factor": 1
#     # "auto.leader.rebalance.enable": true
#     # "auto.create.topics.enable": true
#     # "controlled.shutdown.enable": true
#     # "controlled.shutdown.max.retries": 100

#     ## Options required for external access via NodePort
#     ## ref:
#     ## - http://kafka.apache.org/documentation/#security_configbroker
#     ## - https://cwiki.apache.org/confluence/display/KAFKA/KIP-103%3A+Separation+of+Internal+and+External+traffic
#     ##
#     ## Setting "advertised.listeners" here appends to "PLAINTEXT://${POD_IP}:9092,"
#     # "advertised.listeners": |-
#     #   EXTERNAL://kafka.cluster.local:$((31090 + ${KAFKA_BROKER_ID}))
#     # "listener.security.protocol.map": |-
#     #   PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT

#   ## A collection of additional ports to expose on brokers (formatted as normal containerPort yaml)
#   # Useful when the image exposes metrics (like prometheus, etc.) through a javaagent instead of a sidecar
#   additionalPorts: {}

#   ## Persistence configuration. Specify if and how to persist data to a persistent volume.
#   ##
#   persistence:
#     enabled: false

#     ## The size of the PersistentVolume to allocate to each Kafka Pod in the StatefulSet. For
#     ## production servers this number should likely be much larger.
#     ##
#     size: "1Gi"

#     ## The location within the Kafka container where the PV will mount its storage and Kafka will
#     ## store its logs.
#     ##
#     mountPath: "/opt/kafka/data"

#     ## Kafka data Persistent Volume Storage Class
#     ## If defined, storageClassName: <storageClass>
#     ## If set to "-", storageClassName: "", which disables dynamic provisioning
#     ## If undefined (the default) or set to null, no storageClassName spec is
#     ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
#     ##   GKE, AWS & OpenStack)
#     ##
#     # storageClass:

#   jmx:
#     ## Rules to apply to the Prometheus JMX Exporter.  Note while lots of stats have been cleaned and exposed,
#     ## there are still more stats to clean up and expose, others will never get exposed.  They keep lots of duplicates
#     ## that can be derived easily.  The configMap in this chart cleans up the metrics it exposes to be in a Prometheus
#     ## format, eg topic, broker are labels and not part of metric name. Improvements are gladly accepted and encouraged.
#     configMap:

#       ## Allows disabling the default configmap, note a configMap is needed
#       enabled: true

#       ## Allows setting values to generate confimap
#       ## To allow all metrics through (warning its crazy excessive) comment out below `overrideConfig` and set
#       ## `whitelistObjectNames: []`
#       overrideConfig: {}
#         # jmxUrl: service:jmx:rmi:///jndi/rmi://127.0.0.1:5555/jmxrmi
#         # lowercaseOutputName: true
#         # lowercaseOutputLabelNames: true
#         # ssl: false
#         # rules:
#         # - pattern: ".*"

#       ## If you would like to supply your own ConfigMap for JMX metrics, supply the name of that
#       ## ConfigMap as an `overrideName` here.
#       overrideName: ""

#     ## Port the jmx metrics are exposed in native jmx format, not in Prometheus format
#     port: 5555

#     ## JMX Whitelist Objects, can be set to control which JMX metrics are exposed.  Only whitelisted
#     ## values will be exposed via JMX Exporter.  They must also be exposed via Rules.  To expose all metrics
#     ## (warning its crazy excessive and they aren't formatted in a prometheus style) (1) `whitelistObjectNames: []`
#     ## (2) commented out above `overrideConfig`.
#     whitelistObjectNames:  # []
#     - kafka.controller:*
#     - kafka.server:*
#     - java.lang:*
#     - kafka.network:*
#     - kafka.log:*

#   ## Prometheus Exporters / Metrics
#   ##
#   prometheus:
#     ## Prometheus JMX Exporter: exposes the majority of Kafkas metrics
#     jmx:
#       enabled: false

#       ## The image to use for the metrics collector
#       image: solsson/kafka-prometheus-jmx-exporter@sha256

#       ## The image tag to use for the metrics collector
#       imageTag: a23062396cd5af1acdf76512632c20ea6be76885dfc20cd9ff40fb23846557e8

#       ## Interval at which Prometheus scrapes metrics, note: only used by Prometheus Operator
#       interval: 10s

#       ## Port jmx-exporter exposes Prometheus format metrics to scrape
#       port: 5556

#       resources: {}
#         # limits:
#         #   cpu: 200m
#         #   memory: 1Gi
#         # requests:
#         #   cpu: 100m
#         #   memory: 100Mi

#     ## Prometheus Kafka Exporter: exposes complimentary metrics to JMX Exporter
#     kafka:
#       enabled: false

#       ## The image to use for the metrics collector
#       image: danielqsj/kafka-exporter

#       ## The image tag to use for the metrics collector
#       imageTag: v1.0.1

#       ## Interval at which Prometheus scrapes metrics, note: only used by Prometheus Operator
#       interval: 10s

#       ## Port kafka-exporter exposes for Prometheus to scrape metrics
#       port: 9308

#       ## Resource limits
#       resources: {}
#   #      limits:
#   #        cpu: 200m
#   #        memory: 1Gi
#   #      requests:
#   #        cpu: 100m
#   #        memory: 100Mi

#     operator:
#       ## Are you using Prometheus Operator?
#       enabled: false

#       serviceMonitor:
#         # Namespace Prometheus is installed in
#         namespace: monitoring

#         ## Defaults to whats used if you follow CoreOS [Prometheus Install Instructions](https://github.com/coreos/prometheus-operator/tree/master/helm#tldr)
#         ## [Prometheus Selector Label](https://github.com/coreos/prometheus-operator/blob/master/helm/prometheus/templates/prometheus.yaml#L65)
#         ## [Kube Prometheus Selector Label](https://github.com/coreos/prometheus-operator/blob/master/helm/kube-prometheus/values.yaml#L298)
#         selector:
#           prometheus: kube-prometheus

#   # ------------------------------------------------------------------------------
#   # Zookeeper:
#   # ------------------------------------------------------------------------------

#   zookeeper:
#     ## If true, install the Zookeeper chart alongside Kafka
#     ## ref: https://github.com/kubernetes/charts/tree/master/incubator/zookeeper
#     enabled: true

#     ## ref: https://github.com/kubernetes/contrib/tree/master/statefulsets/zookeeper#stateful-set
#     # Desired quantity of ZooKeeper pods. This should always be (1,3,5, or 7)
#     replicaCount: 1

#     ## Configure Zookeeper resource requests and limits
#     ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
#     resources: ~

#     ## The JVM heap size to allocate to Zookeeper
#     heap: "1G"

#     persistence:
#       enabled: false
#       ## The amount of PV storage allocated to each Zookeeper pod in the statefulset
#       # size: "2Gi"

#     ## Specify a Zookeeper imagePullPolicy
#     ## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images
#     imagePullPolicy: "IfNotPresent"

#     ## If the Zookeeper Chart is disabled a URL and port are required to connect
#     url: ""
#     port: 2181

#     ## Pod scheduling preferences (by default keep pods within a release on separate nodes).
#     ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
#     ## By default we don't set affinity:
#     affinity: {}  # Criteria by which pod label-values influence scheduling for zookeeper pods.
#     # podAntiAffinity:
#     #   requiredDuringSchedulingIgnoredDuringExecution:
#     #     - topologyKey: "kubernetes.io/hostname"
#     #       labelSelector:
#     #         matchLabels:
#     #           release: zookeeper

mongodb:
## Global Docker image registry
## Please, note that this will override the image registry for all the images, including dependencies, configured to use the global value
##
# global:
#   imageRegistry:
  enabled: true
  nameOverride: mongodb

  image:
    ## Bitnami MongoDB registry
    ##
    registry: docker.io
    ## Bitnami MongoDB image name
    ##
    repository: bitnami/mongodb
    ## Bitnami MongoDB image tag
    ## ref: https://hub.docker.com/r/bitnami/mongodb/tags/
    ##
    tag: 4.0.3

    ## Specify a imagePullPolicy
    ## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images
    ##
    pullPolicy: Always
    ## Optionally specify an array of imagePullSecrets.
    ## Secrets must be manually created in the namespace.
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
    ##
    # pullSecrets:
    #   - myRegistrKeySecretName

  ## Enable authentication
  ## ref: https://docs.mongodb.com/manual/tutorial/enable-authentication/
  #
  usePassword: true
  # existingSecret: name-of-existing-secret

  ## MongoDB admin password
  ## ref: https://github.com/bitnami/bitnami-docker-mongodb/blob/master/README.md#setting-the-root-password-on-first-run
  ##
  mongodbRootPassword: adminpass

  ## MongoDB custom user and database
  ## ref: https://github.com/bitnami/bitnami-docker-mongodb/blob/master/README.md#creating-a-user-and-database-on-first-run
  ##
  mongodbUsername: mojaloop
  mongodbPassword: password
  mongodbDatabase: mojaloop


  ## Whether enable/disable IPv6 on MongoDB
  ## ref: https://github.com/bitnami/bitnami-docker-mongodb/blob/master/README.md#enabling/disabling-ipv6
  ##
  mongodbEnableIPv6: true

  ## MongoDB additional command line flags
  ##
  ## Can be used to specify command line flags, for example:
  ##
  ## mongodbExtraFlags:
  ##  - "--wiredTigerCacheSizeGB=2"
  mongodbExtraFlags: []

  ## Pod Security Context
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
  ##
  securityContext:
    enabled: true
    fsGroup: 1001
    runAsUser: 1001

  ## Kubernetes Cluster Domain
  clusterDomain: cluster.local

  ## Kubernetes service type
  service:
    annotations: {}
    type: ClusterIP
    # clusterIP: None
    port: 27017

    ## Specify the nodePort value for the LoadBalancer and NodePort service types.
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport
    ##
    # nodePort:

  ## Setting up replication
  ## ref: https://github.com/bitnami/bitnami-docker-mongodb#setting-up-a-replication
  #
  replicaSet:
    ## Whether to create a MongoDB replica set for high availability or not
    enabled: false
    useHostnames: true

    ## Name of the replica set
    ##
    name: rs0

    ## Key used for replica set authentication
    ##
    # key: key

    ## Number of replicas per each node type
    ##
    replicas:
      secondary: 1
      arbiter: 1
    ## Pod Disruption Budget
    ## ref: https://kubernetes.io/docs/concepts/workloads/pods/disruptions/
    pdb:
      minAvailable:
        primary: 1
        secondary: 1
        arbiter: 1

  # Annotations to be added to MongoDB pods
  podAnnotations: {}

  # Additional pod labels to apply
  podLabels: {}

  ## Configure resource requests and limits
  ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
  ##
  resources: {}
  # limits:
  #   cpu: 500m
  #   memory: 512Mi
  # requests:
  #   cpu: 100m
  #   memory: 256Mi

  ## Node selector
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector
  nodeSelector: {}

  ## Affinity
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  affinity: {}

  ## Tolerations
  ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  tolerations: []

  ## Enable persistence using Persistent Volume Claims
  ## ref: http://kubernetes.io/docs/user-guide/persistent-volumes/
  ##
  persistence:
    enabled: false
    ## A manually managed Persistent Volume and Claim
    ## Requires persistence.enabled: true
    ## If defined, PVC must be created manually before volume will be bound
    # existingClaim:

    ## mongodb data Persistent Volume Storage Class
    ## If defined, storageClassName: <storageClass>
    ## If set to "-", storageClassName: "", which disables dynamic provisioning
    ## If undefined (the default) or set to null, no storageClassName spec is
    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
    ##   GKE, AWS & OpenStack)
    ##
    # storageClass: "-"
    accessModes:
      - ReadWriteOnce
    size: 8Gi
    annotations: {}

  ## Configure extra options for liveness and readiness probes
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes)
  livenessProbe:
    enabled: true
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 6
    successThreshold: 1
  readinessProbe:
    enabled: true
    initialDelaySeconds: 5
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 6
    successThreshold: 1

  # Entries for the MongoDB config file
  configmap:
  #  # Where and how to store data.
  #  storage:
  #    dbPath: /opt/bitnami/mongodb/data/db
  #    journal:
  #      enabled: true
  #    #engine:
  #    #wiredTiger:
  #  # where to write logging data.
  #  systemLog:
  #    destination: file
  #    logAppend: true
  #    path: /opt/bitnami/mongodb/logs/mongodb.log
  #  # network interfaces
  #  net:
  #    port: 27017
  #    bindIp: 0.0.0.0
  #    unixDomainSocket:
  #      enabled: true
  #      pathPrefix: /opt/bitnami/mongodb/tmp
  #  # replica set options
  #  #replication:
  #  #  replSetName: replicaset
  #  # process management options
  #  processManagement:
  #     fork: false
  #     pidFilePath: /opt/bitnami/mongodb/tmp/mongodb.pid
  #  # set parameter options
  #  setParameter:
  #     enableLocalhostAuthBypass: true
  #  # security options
  #  security:
  #  authorization: enabled
     #keyFile: /opt/bitnami/mongodb/conf/keyfile

  ## Prometheus Exporter / Metrics
  ##
  metrics:
    enabled: false

    image:
      registry: docker.io
      repository: forekshub/percona-mongodb-exporter
      tag: latest
      pullPolicy: IfNotPresent
      ## Optionally specify an array of imagePullSecrets.
      ## Secrets must be manually created in the namespace.
      ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
      ##
      # pullSecrets:
      #   - myRegistrKeySecretName

    ## Metrics exporter resource requests and limits
    ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
    ##
    # resources: {}

    ## Metrics exporter pod Annotation
    podAnnotations:
      prometheus.io/scrape: "true"
      prometheus.io/port: "9216"

    ## Prometheus Service Monitor
    ## ref: https://github.com/coreos/prometheus-operator
    ##      https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md
    serviceMonitor:
      ## If the operator is installed in your cluster, set to true to create a Service Monitor Entry
      enabled: false
      ## Used to pass Labels that are used by the Prometheus installed in your cluster to select Service Monitors to work with
      ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#prometheusspec
      additionalLabels: {}

      ## Specify Metric Relabellings to add to the scrape endpoint
      ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#endpoint
      # relabellings:

      alerting:
        ## Define individual alerting rules as required
        ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#rulegroup
        ##      https://prometheus.io/docs/prometheus/latest/configuration/alerting_rules/
        rules: {}

        ## Used to pass Labels that are used by the Prometheus installed in your cluster to select Prometheus Rules to work with
        ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#prometheusspec
  additionalLabels: {}