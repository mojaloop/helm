# Default values for central.
# This is a YAML-formatted file.
# Declare global configurations
global: {}

# Declare variables to be passed into your templates.

ml-api-adapter-service:
  enabled: true
  # Default values for ml-api-adapter.
  # This is a YAML-formatted file.
  # Declare variables to be passed into your templates.
  replicaCount: 1
  image:
    repository: mojaloop/ml-api-adapter
    tag: v9.4.2
    command: '["node", "src/api/index.js"]'
  ## Optionally specify an array of imagePullSecrets.
  ## Secrets must be manually created in the namespace.
  ## ref: https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod
  ##
  #  imagePullSecrets:
  #    - name: myregistrykey
    pullPolicy: Always

  ## Pod scheduling preferences.
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  affinity: {}

  ## Node labels for pod assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector
  nodeSelector: {}

  ## Set toleration for scheduler
  ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  tolerations: []

  sidecar:
    enabled: true
    image:
      repository: mojaloop/event-sidecar
      tag: v9.3.0
      pullPolicy: Always
    readinessProbe:
      enabled: true
      initialDelaySeconds: 120
      periodSeconds: 15
    livenessProbe:
      enabled: true
      initialDelaySeconds: 90
      periodSeconds: 15
    config:
      event_log_grpc_host: localhost
      event_log_grpc_port: 50051
      log_level: info

  init:
    enabled: true
    image:
      name: wait-for-kafka
      repository: solsson/kafka
      tag: latest
      pullPolicy: Always
      command: "until ./bin/kafka-broker-api-versions.sh --bootstrap-server $kafka_host:$kafka_port; do echo waiting for Kafka; sleep 2; done;"
      env: {}
      ## Env example
      # env:
      #   envItem1:
      #     name: hello
      #     value: world
      #

  readinessProbe:
    enabled: true
    httpGet:
      path: /health
    initialDelaySeconds: 120
    periodSeconds: 15
  livenessProbe:
    enabled: true
    httpGet:
      path: /health
    initialDelaySeconds: 90
    periodSeconds: 15

  ## metric configuration for prometheus instrumentation
  metrics:
    ## flag to enable/disable the metrics end-points
    enabled: true

  config:
    # this can be set if the dependency chart for kafka is disabled. If 'kafka_host' is commented out, then the name of the dependency chart will be used.
    kafka_host: '$release_name-kafka'
    kafka_port: 9092
    kafka_partitioner: 'murmur2_random'
    central_services_host: '$release_name-centralledger-service'
    central_services_port: 80
    security:
      callback:
        rejectUnauthorized: true
    max_callback_time_lag_dilation_milliseconds: 100
    max_fulfil_timeout_duration_seconds: 240

    ## Log Configuration
    log_level: info
    log_filter: 'error, warn, info'
    log_transport: file

    ## Health Check endpoint
    central_services_health_endpoint_param: '/health'

    ## Tracing Configuration
    event_trace_vendor: mojaloop
    event_trace_state_enabled: true
    event_log_filter: 'audit:*, log:warn, log:error'
    # If set to true, only the metadata object from the event will be printed.
    event_log_metadata_only: false
    # A comma-separated list of events that should return immediately instead of waiting for the event promises to resolve
    # Any combination of: `log,audit,trace`
    event_async_override: 'log,trace'
    event_traceid_per_vendor: false

    ## Error handling Configuration
    error_handling:
      include_cause_extension: false
      truncate_extensions: true

  service:
    type: ClusterIP
    externalPort: 80
    internalPort: 3000

  ingress:
    enabled: true
    externalPath: /
    # Used to create an Ingress record.
    hosts:
      api: ml-api-adapter.local

    annotations:
      nginx.ingress.kubernetes.io/rewrite-target: '/'
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"
    tls:
      # Secrets must be manually created in the namespace.
      # - secretName: chart-example-tls
      #   hosts:
      #     - chart-example.local
  resources: {}
    # We usually recommend not to specify default resources and to leave this as a conscious
    # choice for the user. This also increases chances charts run on environments with little
    # resources, such as Minikube. If you do want to specify resources, uncomment the following
    # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    # limits:
    #  cpu: 100m
    #  memory: 128Mi
    # requests:
    #  cpu: 100m
    #  memory: 128Mi


ml-api-adapter-handler-notification:
  enabled: true
  # Default values for ml-api-adapter.
  # This is a YAML-formatted file.
  # Declare variables to be passed into your templates.
  replicaCount: 1
  image:
    repository: mojaloop/ml-api-adapter
    tag: v9.4.2
    command: '["node", "src/handlers/index.js", "handler", "--notification"]'
  ## Optionally specify an array of imagePullSecrets.
  ## Secrets must be manually created in the namespace.
  ## ref: https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod
  ##
  #  imagePullSecrets:
  #    - name: myregistrykey
    pullPolicy: Always

  ## Pod scheduling preferences.
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  affinity: {}

  ## Node labels for pod assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector
  nodeSelector: {}

  ## Set toleration for scheduler
  ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  tolerations: []

  sidecar:
    enabled: true
    image:
      repository: mojaloop/event-sidecar
      tag: v9.3.0
      pullPolicy: Always
    readinessProbe:
      enabled: true
      initialDelaySeconds: 120
      periodSeconds: 15
    livenessProbe:
      enabled: true
      initialDelaySeconds: 90
      periodSeconds: 15
    config:
      event_log_grpc_host: localhost
      event_log_grpc_port: 50051
      event_log_filter: 'audit:*, log:info, log:warn, log:error'
      event_log_metadata_only: true
      log_level: info

  init:
    enabled: true

  readinessProbe:
    enabled: true
    httpGet:
      path: /health
    initialDelaySeconds: 120
    periodSeconds: 15
  livenessProbe:
    enabled: true
    httpGet:
      path: /health
    initialDelaySeconds: 90
    periodSeconds: 15

  ## metric configuration for prometheus instrumentation
  metrics:
    ## flag to enable/disable the metrics end-points
    enabled: true

  config:
    # this can be set if the dependency chart for kafka is disabled. If 'kafka_host' is commented out, then the name of the dependency chart will be used.
    kafka_host: '$release_name-kafka'
    kafka_port: 9092
    kafka_partitioner: 'murmur2_random'
    central_services_host: '$release_name-centralledger-service'
    central_services_port: 80
    security:
      callback:
        rejectUnauthorized: true
    max_callback_time_lag_dilation_milliseconds: 100
    max_fulfil_timeout_duration_seconds: 240

    ## Endpoint Cache Configuration
    endpoint_cache_expiresInMs: 180000
    endpoint_cache_generateTimeoutMs: 30000

    ## Send callback confirmation to PayeeFSP in addition to the Mojaloop v1.0 Spec Callback to PayerFSP
    send_transfer_confirmation_to_payee: true

    ## Log Configuration
    log_level: info
    log_filter: 'error, warn, info'
    log_transport: file

    ## Health Check endpoint
    central_services_health_endpoint_param: '/health'

    ## Tracing Configuration
    event_trace_vendor: mojaloop
    event_log_filter: 'audit:*, log:warn, log:error'
    # If set to true, only the metadata object from the event will be printed.
    event_log_metadata_only: false
    # A comma-separated list of events that should return immediately instead of waiting for the event promises to resolve
    # Any combination of: `log,audit,trace`
    event_async_override: 'log,trace'
    event_traceid_per_vendor: false

    ## Error handling Configuration
    error_handling:
      include_cause_extension: false
      truncate_extensions: true

  service:
    type: ClusterIP
    externalPort: 80
    internalPort: 3000

  ingress:
    enabled: true
    externalPath: /
    # Used to create an Ingress record.
    hosts:
      api: ml-api-adapter-notification.local

    annotations:
      nginx.ingress.kubernetes.io/rewrite-target: '/'
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"
    tls:
      # Secrets must be manually created in the namespace.
      # - secretName: chart-example-tls
      #   hosts:
      #     - chart-example.local
  resources: {}
    # We usually recommend not to specify default resources and to leave this as a conscious
    # choice for the user. This also increases chances charts run on environments with little
    # resources, such as Minikube. If you do want to specify resources, uncomment the following
    # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    # limits:
    #  cpu: 100m
    #  memory: 128Mi
    # requests:
    #  cpu: 100m
    #  memory: 128Mi

## This is used for testing ml-api-adapter deployments
#
#kafka:
#  enabled: true
#  nameOverride: kafka
#  # ------------------------------------------------------------------------------
#  # Kafka:
#  # ------------------------------------------------------------------------------
#
#  ## The StatefulSet installs 3 pods by default
#  replicas: 1
#
#  ## The kafka image repository
#  image: "confluentinc/cp-kafka"
#
#  ## The kafka image tag
#  imageTag: "4.0.1-1"
#
#  ## Specify a imagePullPolicy
#  ## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images
#  imagePullPolicy: "IfNotPresent"
#
#  ## Configure resource requests and limits
#  ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
#  resources: {}
#    # limits:
#    #   cpu: 200m
#    #   memory: 1536Mi
#    # requests:
#    #   cpu: 100m
#    #   memory: 1024Mi
#  kafkaHeapOptions: "-Xmx1G -Xms1G"
#
#  ## The StatefulSet Update Strategy which Kafka will use when changes are applied.
#  ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
#  updateStrategy:
#    type: "OnDelete"
#
#  ## Start and stop pods in Parallel or OrderedReady (one-by-one.)  Note - Can not change after first release.
#  ## ref: https://kubernetes.io/docs/tutorials/stateful-application/basic-stateful-set/#pod-management-policy
#  podManagementPolicy: OrderedReady
#
#  ## If RBAC is enabled on the cluster, the Kafka init container needs a service account
#  ## with permissisions sufficient to apply pod labels
#  rbac:
#    enabled: true
#
#  ## The name of the storage class which the cluster should use.
#  # storageClass: default
#
#  ## The subpath within the Kafka container's PV where logs will be stored.
#  ## This is combined with `persistence.mountPath`, to create, by default: /opt/kafka/data/logs
#  logSubPath: "logs"
#
#  ## Use an alternate scheduler, e.g. "stork".
#  ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
#  ##
#  # schedulerName:
#
#  ## Pod scheduling preferences (by default keep pods within a release on separate nodes).
#  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
#  ## By default we don't set affinity
#  affinity: {}
#  ## Alternatively, this typical example defines:
#  ## antiAffinity (to keep Kafka pods on separate pods)
#  ## and affinity (to encourage Kafka pods to be collocated with Zookeeper pods)
#  # affinity:
#  #   podAntiAffinity:
#  #     requiredDuringSchedulingIgnoredDuringExecution:
#  #     - labelSelector:
#  #         matchExpressions:
#  #         - key: app
#  #           operator: In
#  #           values:
#  #           - kafka
#  #       topologyKey: "kubernetes.io/hostname"
#  #   podAffinity:
#  #     preferredDuringSchedulingIgnoredDuringExecution:
#  #      - weight: 50
#  #        podAffinityTerm:
#  #          labelSelector:
#  #            matchExpressions:
#  #            - key: app
#  #              operator: In
#  #              values:
#  #                - zookeeper
#  #          topologyKey: "kubernetes.io/hostname"
#
#  ## Node labels for pod assignment
#  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector
#  nodeSelector: {}
#
#  ## Readiness probe config.
#  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/
#  ##
#  readinessProbe:
#    initialDelaySeconds: 30
#    periodSeconds: 10
#    timeoutSeconds: 5
#    successThreshold: 1
#    failureThreshold: 3
#
#  ## Period to wait for broker graceful shutdown (sigterm) before pod is killed (sigkill)
#  ## ref: https://kubernetes-v1-4.github.io/docs/user-guide/production-pods/#lifecycle-hooks-and-termination-notice
#  ## ref: https://kafka.apache.org/10/documentation.html#brokerconfigs controlled.shutdown.*
#  terminationGracePeriodSeconds: 60
#
#  # Tolerations for nodes that have taints on them.
#  # Useful if you want to dedicate nodes to just run kafka
#  # https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
#  tolerations: []
#  # tolerations:
#  # - key: "key"
#  #   operator: "Equal"
#  #   value: "value"
#  #   effect: "NoSchedule"
#
#  ## External access.
#  ##
#  external:
#    enabled: false
#    servicePort: 19092
#    firstListenerPort: 31090
#    domain: cluster.local
#    init:
#      image: "lwolf/kubectl_deployer"
#      imageTag: "0.4"
#      imagePullPolicy: "IfNotPresent"
#
#  ## Configuration Overrides. Specify any Kafka settings you would like set on the StatefulSet
#  ## here in map format, as defined in the official docs.
#  ## ref: https://kafka.apache.org/documentation/#brokerconfigs
#  ##
#  configurationOverrides:
#    "offsets.topic.replication.factor": 1
#    # "auto.leader.rebalance.enable": true
#    # "auto.create.topics.enable": true
#    # "controlled.shutdown.enable": true
#    # "controlled.shutdown.max.retries": 100
#
#    ## Options required for external access via NodePort
#    ## ref:
#    ## - http://kafka.apache.org/documentation/#security_configbroker
#    ## - https://cwiki.apache.org/confluence/display/KAFKA/KIP-103%3A+Separation+of+Internal+and+External+traffic
#    ##
#    ## Setting "advertised.listeners" here appends to "PLAINTEXT://${POD_IP}:9092,"
#    # "advertised.listeners": |-
#    #   EXTERNAL://kafka.cluster.local:$((31090 + ${KAFKA_BROKER_ID}))
#    # "listener.security.protocol.map": |-
#    #   PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
#
#  ## A collection of additional ports to expose on brokers (formatted as normal containerPort yaml)
#  # Useful when the image exposes metrics (like prometheus, etc.) through a javaagent instead of a sidecar
#  additionalPorts: {}
#
#  ## Persistence configuration. Specify if and how to persist data to a persistent volume.
#  ##
#  persistence:
#    enabled: false
#
#    ## The size of the PersistentVolume to allocate to each Kafka Pod in the StatefulSet. For
#    ## production servers this number should likely be much larger.
#    ##
#    size: "1Gi"
#
#    ## The location within the Kafka container where the PV will mount its storage and Kafka will
#    ## store its logs.
#    ##
#    mountPath: "/opt/kafka/data"
#
#    ## Kafka data Persistent Volume Storage Class
#    ## If defined, storageClassName: <storageClass>
#    ## If set to "-", storageClassName: "", which disables dynamic provisioning
#    ## If undefined (the default) or set to null, no storageClassName spec is
#    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
#    ##   GKE, AWS & OpenStack)
#    ##
#    # storageClass:
#
#  jmx:
#    ## Rules to apply to the Prometheus JMX Exporter.  Note while lots of stats have been cleaned and exposed,
#    ## there are still more stats to clean up and expose, others will never get exposed.  They keep lots of duplicates
#    ## that can be derived easily.  The configMap in this chart cleans up the metrics it exposes to be in a Prometheus
#    ## format, eg topic, broker are labels and not part of metric name. Improvements are gladly accepted and encouraged.
#    configMap:
#
#      ## Allows disabling the default configmap, note a configMap is needed
#      enabled: true
#
#      ## Allows setting values to generate confimap
#      ## To allow all metrics through (warning its crazy excessive) comment out below `overrideConfig` and set
#      ## `whitelistObjectNames: []`
#      overrideConfig: {}
#        # jmxUrl: service:jmx:rmi:///jndi/rmi://127.0.0.1:5555/jmxrmi
#        # lowercaseOutputName: true
#        # lowercaseOutputLabelNames: true
#        # ssl: false
#        # rules:
#        # - pattern: ".*"
#
#      ## If you would like to supply your own ConfigMap for JMX metrics, supply the name of that
#      ## ConfigMap as an `overrideName` here.
#      overrideName: ""
#
#    ## Port the jmx metrics are exposed in native jmx format, not in Prometheus format
#    port: 5555
#
#    ## JMX Whitelist Objects, can be set to control which JMX metrics are exposed.  Only whitelisted
#    ## values will be exposed via JMX Exporter.  They must also be exposed via Rules.  To expose all metrics
#    ## (warning its crazy excessive and they aren't formatted in a prometheus style) (1) `whitelistObjectNames: []`
#    ## (2) commented out above `overrideConfig`.
#    whitelistObjectNames:  # []
#    - kafka.controller:*
#    - kafka.server:*
#    - java.lang:*
#    - kafka.network:*
#    - kafka.log:*
#
#  ## Prometheus Exporters / Metrics
#  ##
#  prometheus:
#    ## Prometheus JMX Exporter: exposes the majority of Kafkas metrics
#    jmx:
#      enabled: false
#
#      ## The image to use for the metrics collector
#      image: solsson/kafka-prometheus-jmx-exporter@sha256
#
#      ## The image tag to use for the metrics collector
#      imageTag: a23062396cd5af1acdf76512632c20ea6be76885dfc20cd9ff40fb23846557e8
#
#      ## Interval at which Prometheus scrapes metrics, note: only used by Prometheus Operator
#      interval: 10s
#
#      ## Port jmx-exporter exposes Prometheus format metrics to scrape
#      port: 5556
#
#      resources: {}
#        # limits:
#        #   cpu: 200m
#        #   memory: 1Gi
#        # requests:
#        #   cpu: 100m
#        #   memory: 100Mi
#
#    ## Prometheus Kafka Exporter: exposes complimentary metrics to JMX Exporter
#    kafka:
#      enabled: false
#
#      ## The image to use for the metrics collector
#      image: danielqsj/kafka-exporter
#
#      ## The image tag to use for the metrics collector
#      imageTag: v1.0.1
#
#      ## Interval at which Prometheus scrapes metrics, note: only used by Prometheus Operator
#      interval: 10s
#
#      ## Port kafka-exporter exposes for Prometheus to scrape metrics
#      port: 9308
#
#      ## Resource limits
#      resources: {}
#  #      limits:
#  #        cpu: 200m
#  #        memory: 1Gi
#  #      requests:
#  #        cpu: 100m
#  #        memory: 100Mi
#
#    operator:
#      ## Are you using Prometheus Operator?
#      enabled: false
#
#      serviceMonitor:
#        # Namespace Prometheus is installed in
#        namespace: monitoring
#
#        ## Defaults to whats used if you follow CoreOS [Prometheus Install Instructions](https://github.com/coreos/prometheus-operator/tree/master/helm#tldr)
#        ## [Prometheus Selector Label](https://github.com/coreos/prometheus-operator/blob/master/helm/prometheus/templates/prometheus.yaml#L65)
#        ## [Kube Prometheus Selector Label](https://github.com/coreos/prometheus-operator/blob/master/helm/kube-prometheus/values.yaml#L298)
#        selector:
#          prometheus: kube-prometheus
