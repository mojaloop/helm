# Default values for central.
# This is a YAML-formatted file.
# Declare global configurations
global:
  config:
    ## Pod scheduling preferences.
    ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
    ##
    affinity: {}

    ## Node labels for pod assignment
    ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector
    nodeSelector: {}

    ## Set toleration for schedular
    ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
    tolerations: []

# Declare variables to be passed into your templates.

ml-api-adapter-service:
  enabled: true
  # Default values for ml-api-adapter.
  # This is a YAML-formatted file.
  # Declare variables to be passed into your templates.
  replicaCount: 1
  image:
    repository: mojaloop/ml-api-adapter
    tag: v3.7.8-snapshot
    command: '["node", "src/api/index.js"]'
  ## Optionally specify an array of imagePullSecrets.
  ## Secrets must be manually created in the namespace.
  ## ref: https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod
  ##
  #  imagePullSecrets:
  #    - name: myregistrykey
    pullPolicy: Always

  readinessProbe:
    enabled: true
    httpGet:
      path: /health
    initialDelaySeconds: 120
    periodSeconds: 15
  livenessProbe:
    enabled: true
    httpGet:
      path: /health
    initialDelaySeconds: 90
    periodSeconds: 15

  config:
    # this can be set if the dependency chart for kafka is disabled. If 'kafka_host' is commented out, then the name of the dependency chart will be used.
    kafka_host: kafka
    kafka_port: 9092
    # default_json config for nodejs. The following variables will be injected by the helm chart (see config.yaml):  $ingress_host, $ingress_port, $kafka_host, $kafka_port
    default_json: |
          {
            "PORT": $ingress_port,
            "HOSTNAME": "$ingress_host",
            "ENDPOINT_SOURCE_URL": "http://perf1-central-ledger.mojaloop.live/admin/participants/{{fsp}}/endpoints",
            "ENDPOINT_CACHE_CONFIG": {
              "expiresIn": 180000,
              "generateTimeout": 30000
            },
            "AMOUNT": {
              "PRECISION": 10,
              "SCALE": 2
            },
            "HANDLERS": {
             "DISABLED": true,
             "API": {
               "DISABLED": false
             }
            },
            "INSTRUMENTATION": {
              "METRICS": {
                "DISABLED": false,
                "config": {
                  "timeout": 5000,
                  "prefix": "moja_ml_service_"
                }
              }
            },
            "KAFKA": {
              "TOPIC_TEMPLATES": {
                "PARTICIPANT_TOPIC_TEMPLATE": {
                  "TEMPLATE": "topic-{{participantName}}-{{functionality}}-{{action}}",
                  "REGEX": "topic-(.*)-(.*)-(.*)"
                },
                "NOTIFICATION_TOPIC_TEMPLATE": {
                  "TEMPLATE": "topic-notification-event",
                  "REGEX": "topic-notification-event"
                },
                "FULFIL_TOPIC_TEMPLATE": {
                  "TEMPLATE": "topic-transfer-fulfil",
                  "REGEX": "topic-transfer-fulfil"
                }
              },
              "CONSUMER": {
                "NOTIFICATION": {
                  "EVENT": {
                    "config": {
                      "options": {
                        "mode": 2,
                        "batchSize": 1,
                        "recursiveTimeout": 100,
                        "messageCharset": "utf8",
                        "messageAsJSON": true,
                        "sync": true,
                        "consumeTimeout": 1000
                      },
                      "rdkafkaConf": {
                        "client.id": "ml-con-notification-event",
                        "group.id": "kafka-ml-api-adapter",
                        "metadata.broker.list": "$kafka_host:$kafka_port",
                        "socket.blocking.max.ms": 1,
                        "fetch.wait.max.ms": 1,
                        "fetch.error.backoff.ms": 1,
                        "queue.buffering.max.ms": 1,
                        "broker.version.fallback": "0.10.1.0",
                        "api.version.request": true,
                        "enable.auto.commit": false,
                        "auto.commit.interval.ms": 200,
                        "socket.keepalive.enable": true,
                        "socket.max.fails": 1,
                        "partition.assignment.strategy": "range"
                      },
                      "topicConf": {
                        "auto.offset.reset": "earliest"
                      }
                    }
                  }
                }
              },
              "PRODUCER": {
                "TRANSFER": {
                  "PREPARE": {
                    "config": {
                      "options": {
                        "messageCharset": "utf8"
                      },
                      "rdkafkaConf": {
                        "metadata.broker.list": "$kafka_host:$kafka_port",
                        "client.id": "ml-prod-transfer-prepare",
                        "event_cb": true,
                        "compression.codec": "none",
                        "retry.backoff.ms": 100,
                        "message.send.max.retries": 2,
                        "socket.keepalive.enable": true,
                        "socket.max.fails": 0,
                        "queue.buffering.max.messages": 10000000,
                        "queue.buffering.max.ms": 50,
                        "batch.num.messages": 100,
                        "api.version.request": true,
                        "dr_cb": true
                      }
                    }
                  },
                  "FULFIL": {
                    "config": {
                      "options": {
                        "messageCharset": "utf8"
                      },
                      "rdkafkaConf": {
                        "metadata.broker.list": "$kafka_host:$kafka_port",
                        "client.id": "ml-prod-transfer-fulfil",
                        "event_cb": true,
                        "compression.codec": "none",
                        "retry.backoff.ms": 100,
                        "message.send.max.retries": 2,
                        "socket.keepalive.enable": true,
                        "socket.max.fails": 0,
                        "queue.buffering.max.messages": 10000000,
                        "queue.buffering.max.ms": 50,
                        "batch.num.messages": 100,
                        "api.version.request": true,
                        "dr_cb": true
                      }
                    }
                  }
                }
              }
            }
          }

  service:
    name: ml-api-adapter
    type: ClusterIP
    externalPort: 8088
    internalPort: 8088

  ingress:
    enabled: true
    externalPath: /
    # Used to create an Ingress record.
    hosts:
      api: ml-api-adapter.local

    annotations:
      nginx.ingress.kubernetes.io/rewrite-target: '/'
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"
    tls:
      # Secrets must be manually created in the namespace.
      # - secretName: chart-example-tls
      #   hosts:
      #     - chart-example.local
  resources: {}
    # We usually recommend not to specify default resources and to leave this as a conscious
    # choice for the user. This also increases chances charts run on environments with little
    # resources, such as Minikube. If you do want to specify resources, uncomment the following
    # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    # limits:
    #  cpu: 100m
    #  memory: 128Mi
    # requests:
    #  cpu: 100m
    #  memory: 128Mi


ml-api-adapter-handler-notification:
  enabled: true
  # Default values for ml-api-adapter.
  # This is a YAML-formatted file.
  # Declare variables to be passed into your templates.
  replicaCount: 1
  image:
    repository: mojaloop/ml-api-adapter
    tag: v3.7.8-snapshot
    command: '["node", "src/handlers/index.js", "handler", "--notification"]'
  ## Optionally specify an array of imagePullSecrets.
  ## Secrets must be manually created in the namespace.
  ## ref: https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod
  ##
  #  imagePullSecrets:
  #    - name: myregistrykey
    pullPolicy: Always

  init:
    enabled: true

  readinessProbe:
    enabled: true
    httpGet:
      path: /health
    initialDelaySeconds: 120
    periodSeconds: 15
  livenessProbe:
    enabled: true
    httpGet:
      path: /health
    initialDelaySeconds: 90
    periodSeconds: 15

  config:
    # this can be set if the dependency chart for kafka is disabled. If 'kafka_host' is commented out, then the name of the dependency chart will be used.
    kafka_host: kafka
    kafka_port: 9092
    # default_json config for nodejs. The following variables will be injected by the helm chart (see config.yaml):  $ingress_host, $ingress_port, $kafka_host, $kafka_port
    default_json: |
          {
            "PORT": $ingress_port,
            "HOSTNAME": "$ingress_host",
            "ENDPOINT_SOURCE_URL": "http://perf1-central-ledger.mojaloop.live/admin/participants/{{fsp}}/endpoints",
            "ENDPOINT_CACHE_CONFIG": {
              "expiresIn": 180000,
              "generateTimeout": 30000
            },
            "AMOUNT": {
              "PRECISION": 10,
              "SCALE": 2
            },
            "HANDLERS": {
             "DISABLED": false,
             "API": {
               "DISABLED": false
             }
            },
            "INSTRUMENTATION": {
              "METRICS": {
                "DISABLED": false,
                "config": {
                  "timeout": 5000,
                  "prefix": "moja_ml_notifi_hand_"
                }
              }
            },
            "KAFKA": {
              "TOPIC_TEMPLATES": {
                "PARTICIPANT_TOPIC_TEMPLATE": {
                  "TEMPLATE": "topic-{{participantName}}-{{functionality}}-{{action}}",
                  "REGEX": "topic-(.*)-(.*)-(.*)"
                },
                "NOTIFICATION_TOPIC_TEMPLATE": {
                  "TEMPLATE": "topic-notification-event",
                  "REGEX": "topic-notification-event"
                },
                "FULFIL_TOPIC_TEMPLATE": {
                  "TEMPLATE": "topic-transfer-fulfil",
                  "REGEX": "topic-transfer-fulfil"
                }
              },
              "CONSUMER": {
                "NOTIFICATION": {
                  "EVENT": {
                    "config": {
                      "options": {
                        "mode": 2,
                        "batchSize": 1,
                        "recursiveTimeout": 100,
                        "messageCharset": "utf8",
                        "messageAsJSON": true,
                        "sync": true,
                        "consumeTimeout": 1000
                      },
                      "rdkafkaConf": {
                        "client.id": "ml-con-notification-event",
                        "group.id": "kafka-ml-api-adapter",
                        "metadata.broker.list": "$kafka_host:$kafka_port",
                        "socket.blocking.max.ms": 1,
                        "fetch.wait.max.ms": 1,
                        "fetch.error.backoff.ms": 1,
                        "queue.buffering.max.ms": 1,
                        "broker.version.fallback": "0.10.1.0",
                        "api.version.request": true,
                        "enable.auto.commit": false,
                        "auto.commit.interval.ms": 200,
                        "socket.keepalive.enable": true,
                        "socket.max.fails": 1,
                        "partition.assignment.strategy": "range"
                      },
                      "topicConf": {
                        "auto.offset.reset": "earliest"
                      }
                    }
                  }
                }
              },
              "PRODUCER": {
                "TRANSFER": {
                  "PREPARE": {
                    "config": {
                      "options": {
                        "messageCharset": "utf8"
                      },
                      "rdkafkaConf": {
                        "metadata.broker.list": "$kafka_host:$kafka_port",
                        "client.id": "ml-prod-transfer-prepare",
                        "event_cb": true,
                        "compression.codec": "none",
                        "retry.backoff.ms": 100,
                        "message.send.max.retries": 2,
                        "socket.keepalive.enable": true,
                        "socket.max.fails": 0,
                        "queue.buffering.max.messages": 10000000,
                        "queue.buffering.max.ms": 50,
                        "batch.num.messages": 100,
                        "api.version.request": true,
                        "dr_cb": true,
                        "partitioner": "random"
                      }
                    }
                  },
                  "FULFIL": {
                    "config": {
                      "options": {
                        "messageCharset": "utf8"
                      },
                      "rdkafkaConf": {
                        "metadata.broker.list": "$kafka_host:$kafka_port",
                        "client.id": "ml-prod-transfer-fulfil",
                        "event_cb": true,
                        "compression.codec": "none",
                        "retry.backoff.ms": 100,
                        "message.send.max.retries": 2,
                        "socket.keepalive.enable": true,
                        "socket.max.fails": 0,
                        "queue.buffering.max.messages": 10000000,
                        "queue.buffering.max.ms": 50,
                        "batch.num.messages": 100,
                        "api.version.request": true,
                        "dr_cb": true,
                        "partitioner": "random"
                      }
                    }
                  }
                }
              }
            }
          }

  service:
    name: ml-api-adapter
    type: ClusterIP
    externalPort: 8088
    internalPort: 8088

  ingress:
    enabled: true
    externalPath: /
    # Used to create an Ingress record.
    hosts:
      api: ml-api-adapter-notification.local

    annotations:
      nginx.ingress.kubernetes.io/rewrite-target: '/'
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"
    tls:
      # Secrets must be manually created in the namespace.
      # - secretName: chart-example-tls
      #   hosts:
      #     - chart-example.local
  resources: {}
    # We usually recommend not to specify default resources and to leave this as a conscious
    # choice for the user. This also increases chances charts run on environments with little
    # resources, such as Minikube. If you do want to specify resources, uncomment the following
    # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    # limits:
    #  cpu: 100m
    #  memory: 128Mi
    # requests:
    #  cpu: 100m
    #  memory: 128Mi

## This is used for testing ml-api-adapter deployments
#
#kafka:
#  enabled: true
#  nameOverride: kafka
#  # ------------------------------------------------------------------------------
#  # Kafka:
#  # ------------------------------------------------------------------------------
#
#  ## The StatefulSet installs 3 pods by default
#  replicas: 1
#
#  ## The kafka image repository
#  image: "confluentinc/cp-kafka"
#
#  ## The kafka image tag
#  imageTag: "4.0.1-1"
#
#  ## Specify a imagePullPolicy
#  ## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images
#  imagePullPolicy: "IfNotPresent"
#
#  ## Configure resource requests and limits
#  ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
#  resources: {}
#    # limits:
#    #   cpu: 200m
#    #   memory: 1536Mi
#    # requests:
#    #   cpu: 100m
#    #   memory: 1024Mi
#  kafkaHeapOptions: "-Xmx1G -Xms1G"
#
#  ## The StatefulSet Update Strategy which Kafka will use when changes are applied.
#  ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
#  updateStrategy:
#    type: "OnDelete"
#
#  ## Start and stop pods in Parallel or OrderedReady (one-by-one.)  Note - Can not change after first release.
#  ## ref: https://kubernetes.io/docs/tutorials/stateful-application/basic-stateful-set/#pod-management-policy
#  podManagementPolicy: OrderedReady
#
#  ## If RBAC is enabled on the cluster, the Kafka init container needs a service account
#  ## with permissisions sufficient to apply pod labels
#  rbac:
#    enabled: true
#
#  ## The name of the storage class which the cluster should use.
#  # storageClass: default
#
#  ## The subpath within the Kafka container's PV where logs will be stored.
#  ## This is combined with `persistence.mountPath`, to create, by default: /opt/kafka/data/logs
#  logSubPath: "logs"
#
#  ## Use an alternate scheduler, e.g. "stork".
#  ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
#  ##
#  # schedulerName:
#
#  ## Pod scheduling preferences (by default keep pods within a release on separate nodes).
#  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
#  ## By default we don't set affinity
#  affinity: {}
#  ## Alternatively, this typical example defines:
#  ## antiAffinity (to keep Kafka pods on separate pods)
#  ## and affinity (to encourage Kafka pods to be collocated with Zookeeper pods)
#  # affinity:
#  #   podAntiAffinity:
#  #     requiredDuringSchedulingIgnoredDuringExecution:
#  #     - labelSelector:
#  #         matchExpressions:
#  #         - key: app
#  #           operator: In
#  #           values:
#  #           - kafka
#  #       topologyKey: "kubernetes.io/hostname"
#  #   podAffinity:
#  #     preferredDuringSchedulingIgnoredDuringExecution:
#  #      - weight: 50
#  #        podAffinityTerm:
#  #          labelSelector:
#  #            matchExpressions:
#  #            - key: app
#  #              operator: In
#  #              values:
#  #                - zookeeper
#  #          topologyKey: "kubernetes.io/hostname"
#
#  ## Node labels for pod assignment
#  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector
#  nodeSelector: {}
#
#  ## Readiness probe config.
#  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/
#  ##
#  readinessProbe:
#    initialDelaySeconds: 30
#    periodSeconds: 10
#    timeoutSeconds: 5
#    successThreshold: 1
#    failureThreshold: 3
#
#  ## Period to wait for broker graceful shutdown (sigterm) before pod is killed (sigkill)
#  ## ref: https://kubernetes-v1-4.github.io/docs/user-guide/production-pods/#lifecycle-hooks-and-termination-notice
#  ## ref: https://kafka.apache.org/10/documentation.html#brokerconfigs controlled.shutdown.*
#  terminationGracePeriodSeconds: 60
#
#  # Tolerations for nodes that have taints on them.
#  # Useful if you want to dedicate nodes to just run kafka
#  # https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
#  tolerations: []
#  # tolerations:
#  # - key: "key"
#  #   operator: "Equal"
#  #   value: "value"
#  #   effect: "NoSchedule"
#
#  ## External access.
#  ##
#  external:
#    enabled: false
#    servicePort: 19092
#    firstListenerPort: 31090
#    domain: cluster.local
#    init:
#      image: "lwolf/kubectl_deployer"
#      imageTag: "0.4"
#      imagePullPolicy: "IfNotPresent"
#
#  ## Configuration Overrides. Specify any Kafka settings you would like set on the StatefulSet
#  ## here in map format, as defined in the official docs.
#  ## ref: https://kafka.apache.org/documentation/#brokerconfigs
#  ##
#  configurationOverrides:
#    "offsets.topic.replication.factor": 1
#    # "auto.leader.rebalance.enable": true
#    # "auto.create.topics.enable": true
#    # "controlled.shutdown.enable": true
#    # "controlled.shutdown.max.retries": 100
#
#    ## Options required for external access via NodePort
#    ## ref:
#    ## - http://kafka.apache.org/documentation/#security_configbroker
#    ## - https://cwiki.apache.org/confluence/display/KAFKA/KIP-103%3A+Separation+of+Internal+and+External+traffic
#    ##
#    ## Setting "advertised.listeners" here appends to "PLAINTEXT://${POD_IP}:9092,"
#    # "advertised.listeners": |-
#    #   EXTERNAL://kafka.cluster.local:$((31090 + ${KAFKA_BROKER_ID}))
#    # "listener.security.protocol.map": |-
#    #   PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
#
#  ## A collection of additional ports to expose on brokers (formatted as normal containerPort yaml)
#  # Useful when the image exposes metrics (like prometheus, etc.) through a javaagent instead of a sidecar
#  additionalPorts: {}
#
#  ## Persistence configuration. Specify if and how to persist data to a persistent volume.
#  ##
#  persistence:
#    enabled: false
#
#    ## The size of the PersistentVolume to allocate to each Kafka Pod in the StatefulSet. For
#    ## production servers this number should likely be much larger.
#    ##
#    size: "1Gi"
#
#    ## The location within the Kafka container where the PV will mount its storage and Kafka will
#    ## store its logs.
#    ##
#    mountPath: "/opt/kafka/data"
#
#    ## Kafka data Persistent Volume Storage Class
#    ## If defined, storageClassName: <storageClass>
#    ## If set to "-", storageClassName: "", which disables dynamic provisioning
#    ## If undefined (the default) or set to null, no storageClassName spec is
#    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
#    ##   GKE, AWS & OpenStack)
#    ##
#    # storageClass:
#
#  jmx:
#    ## Rules to apply to the Prometheus JMX Exporter.  Note while lots of stats have been cleaned and exposed,
#    ## there are still more stats to clean up and expose, others will never get exposed.  They keep lots of duplicates
#    ## that can be derived easily.  The configMap in this chart cleans up the metrics it exposes to be in a Prometheus
#    ## format, eg topic, broker are labels and not part of metric name. Improvements are gladly accepted and encouraged.
#    configMap:
#
#      ## Allows disabling the default configmap, note a configMap is needed
#      enabled: true
#
#      ## Allows setting values to generate confimap
#      ## To allow all metrics through (warning its crazy excessive) comment out below `overrideConfig` and set
#      ## `whitelistObjectNames: []`
#      overrideConfig: {}
#        # jmxUrl: service:jmx:rmi:///jndi/rmi://127.0.0.1:5555/jmxrmi
#        # lowercaseOutputName: true
#        # lowercaseOutputLabelNames: true
#        # ssl: false
#        # rules:
#        # - pattern: ".*"
#
#      ## If you would like to supply your own ConfigMap for JMX metrics, supply the name of that
#      ## ConfigMap as an `overrideName` here.
#      overrideName: ""
#
#    ## Port the jmx metrics are exposed in native jmx format, not in Prometheus format
#    port: 5555
#
#    ## JMX Whitelist Objects, can be set to control which JMX metrics are exposed.  Only whitelisted
#    ## values will be exposed via JMX Exporter.  They must also be exposed via Rules.  To expose all metrics
#    ## (warning its crazy excessive and they aren't formatted in a prometheus style) (1) `whitelistObjectNames: []`
#    ## (2) commented out above `overrideConfig`.
#    whitelistObjectNames:  # []
#    - kafka.controller:*
#    - kafka.server:*
#    - java.lang:*
#    - kafka.network:*
#    - kafka.log:*
#
#  ## Prometheus Exporters / Metrics
#  ##
#  prometheus:
#    ## Prometheus JMX Exporter: exposes the majority of Kafkas metrics
#    jmx:
#      enabled: false
#
#      ## The image to use for the metrics collector
#      image: solsson/kafka-prometheus-jmx-exporter@sha256
#
#      ## The image tag to use for the metrics collector
#      imageTag: a23062396cd5af1acdf76512632c20ea6be76885dfc20cd9ff40fb23846557e8
#
#      ## Interval at which Prometheus scrapes metrics, note: only used by Prometheus Operator
#      interval: 10s
#
#      ## Port jmx-exporter exposes Prometheus format metrics to scrape
#      port: 5556
#
#      resources: {}
#        # limits:
#        #   cpu: 200m
#        #   memory: 1Gi
#        # requests:
#        #   cpu: 100m
#        #   memory: 100Mi
#
#    ## Prometheus Kafka Exporter: exposes complimentary metrics to JMX Exporter
#    kafka:
#      enabled: false
#
#      ## The image to use for the metrics collector
#      image: danielqsj/kafka-exporter
#
#      ## The image tag to use for the metrics collector
#      imageTag: v1.0.1
#
#      ## Interval at which Prometheus scrapes metrics, note: only used by Prometheus Operator
#      interval: 10s
#
#      ## Port kafka-exporter exposes for Prometheus to scrape metrics
#      port: 9308
#
#      ## Resource limits
#      resources: {}
#  #      limits:
#  #        cpu: 200m
#  #        memory: 1Gi
#  #      requests:
#  #        cpu: 100m
#  #        memory: 100Mi
#
#    operator:
#      ## Are you using Prometheus Operator?
#      enabled: false
#
#      serviceMonitor:
#        # Namespace Prometheus is installed in
#        namespace: monitoring
#
#        ## Defaults to whats used if you follow CoreOS [Prometheus Install Instructions](https://github.com/coreos/prometheus-operator/tree/master/helm#tldr)
#        ## [Prometheus Selector Label](https://github.com/coreos/prometheus-operator/blob/master/helm/prometheus/templates/prometheus.yaml#L65)
#        ## [Kube Prometheus Selector Label](https://github.com/coreos/prometheus-operator/blob/master/helm/kube-prometheus/values.yaml#L298)
#        selector:
#          prometheus: kube-prometheus
